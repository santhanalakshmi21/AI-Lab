#!/usr/bin/env python
# coding: utf-8

# In[2]:


get_ipython().system('pip install nltk')
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
import string

# download required NLTK data
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

# define text to be preprocessed
text = "This is a sample sentence, showing off the stop words filtration, tokenization, and lemmatization."

# convert text to lowercase
text = text.lower()

# remove punctuation
text = text.translate(str.maketrans('', '', string.punctuation))

# tokenize text into words
words = word_tokenize(text)

# remove stop words
stop_words = set(stopwords.words('english'))
filtered_words = [word for word in words if word not in stop_words]

# lemmatize words
lemmatizer = WordNetLemmatizer()
lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]

# join lemmatized words back into sentence
preprocessed_text = ' '.join(lemmatized_words)

print(preprocessed_text)


# In[3]:


# -*- coding: utf-8 -*-
"""NLP

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AboboeLS90i1miFVt4B4_SL1Z2pMBPMr
"""

import nltk
nltk.download('vader_lexicon')

from nltk.sentiment.vader import SentimentIntensityAnalyzer

# Initialize the sentiment analyzer
sia = SentimentIntensityAnalyzer()

# Sample text for analysis
text = "I really enjoyed this movie. The acting was great and the plot was engaging."

# Calculate the sentiment score for the text
score = sia.polarity_scores(text)

# Print the sentiment score
print("negative = ", score["neg"])
print("neutral = ", score["neu"])
print("positive = ", score["pos"])
print("compound = ", score["compound"])


# In[ ]:




